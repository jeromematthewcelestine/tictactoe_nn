{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TicTacToe with a neural network\n",
    "\n",
    "In this notebook, I build a simple neural network model to model optimal play in the game tic-tac-toe.\n",
    "\n",
    "I train the neural network model on optimal play data generated by tic-tac-toe \"solver,\" which solves tic-tac-toe by backward induction (and a complete search of the game tree).\n",
    "\n",
    "The goal is see how well a neural net model, trained on an incomplete set of optimal play data, can generalize to board states it has not been trained on. I am exploring this with the goal of doing a similar exercise for the card game No Thanks! -- I am using tic-tac-toe as a simple test case.\n",
    "\n",
    "## Generating optimal play data\n",
    "\n",
    "First, let's generate the optimal play data used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>player</th>\n",
       "      <th>board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, (1, 2, 1, 2, 1, 2, 2, 1, 0))</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2, 1, 2, 1, 2, 2, 1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, (1, 2, 1, 2, 1, 2, 0, 1, 2))</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2, 1, 2, 1, 2, 0, 1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, (1, 2, 1, 2, 1, 2, 0, 1, 0))</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2, 1, 2, 1, 2, 0, 1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, (1, 2, 1, 2, 1, 2, 0, 0, 0))</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2, 1, 2, 1, 2, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, (1, 2, 1, 2, 1, 1, 2, 2, 0))</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2, 1, 2, 1, 1, 2, 2, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              state  action  player  \\\n",
       "0  (0, (1, 2, 1, 2, 1, 2, 2, 1, 0))       8       0   \n",
       "1  (0, (1, 2, 1, 2, 1, 2, 0, 1, 2))       6       0   \n",
       "2  (1, (1, 2, 1, 2, 1, 2, 0, 1, 0))       6       1   \n",
       "3  (0, (1, 2, 1, 2, 1, 2, 0, 0, 0))       6       0   \n",
       "4  (0, (1, 2, 1, 2, 1, 1, 2, 2, 0))       8       0   \n",
       "\n",
       "                         board  \n",
       "0  (1, 2, 1, 2, 1, 2, 2, 1, 0)  \n",
       "1  (1, 2, 1, 2, 1, 2, 0, 1, 2)  \n",
       "2  (1, 2, 1, 2, 1, 2, 0, 1, 0)  \n",
       "3  (1, 2, 1, 2, 1, 2, 0, 0, 0)  \n",
       "4  (1, 2, 1, 2, 1, 1, 2, 2, 0)  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tictactoe_solver\n",
    "import tictactoe\n",
    "import pandas as pd\n",
    "\n",
    "game = tictactoe.TicTacToeGame()\n",
    "solver = tictactoe_solver.TicTacToeSolver(game)\n",
    "solver.solve()\n",
    "\n",
    "data = solver.action_dict\n",
    "\n",
    "df = pd.DataFrame(list(data.items()), columns=[\"state\", \"action\"])\n",
    "df[['player', 'board']] = df['state'].apply(pd.Series)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, each row in our data corresponds to a board state and an action, which our solver has determined is optimal, given the board state. In theory, the `player' field (representing the active player) is redundant, since it can be deduced from the board state, but I plan to include it as a feature for the neural network. While it must be possible for the neural net to learn the active player given the board state, there is no need for us to insist on that, when we can simply provide the active player as an additional input.\n",
    "\n",
    "Next, let's convert the state-action data into a form that can be fed into the PyTorch neural net model.\n",
    "\n",
    "We split the board state into two 'channels' (one 1x9 vector for player 1's pieces, another 1x9 vector for player 2's pieces) and concatenate the two channels, along with the active player (0 and 1 representing player 1 and player 2, respectively), resulting in a 1x19 vector. This in the _input_ vector.\n",
    "\n",
    "We also create a one-hot encoded version of the action field. This is the _target_ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      player  board_0  board_1  board_2  board_3  board_4  board_5  board_6  \\\n",
      "2790       0        2        0        1        2        1        1        0   \n",
      "1112       1        1        1        0        0        2        2        1   \n",
      "1615       0        2        1        1        0        0        1        0   \n",
      "1998       1        0        1        2        1        2        0        1   \n",
      "4192       0        0        0        0        0        1        2        0   \n",
      "\n",
      "      board_7  board_8  action_0  action_1  action_2  action_3  action_4  \\\n",
      "2790        0        2         0         0         0         0         0   \n",
      "1112        0        0         0         0         0         1         0   \n",
      "1615        2        2         0         0         0         1         0   \n",
      "1998        2        1         1         0         0         0         0   \n",
      "4192        2        1         1         0         0         0         0   \n",
      "\n",
      "      action_5  action_6  action_7  action_8  \n",
      "2790         0         1         0         0  \n",
      "1112         0         0         0         0  \n",
      "1615         0         0         0         0  \n",
      "1998         0         0         0         0  \n",
      "4192         0         0         0         0  \n",
      "[[0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1]\n",
      " [1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1]\n",
      " [1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]]\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "board_colnames = ['board_' + str(i) for i in range(9)]\n",
    "df[board_colnames] = df['board'].apply(pd.Series)\n",
    "\n",
    "action_dummies = pd.get_dummies(df['action'], prefix='action')\n",
    "df2 = pd.concat([df, action_dummies], axis=1)\n",
    "\n",
    "action_colnames = ['action_' + str(i) for i in range(9)]\n",
    "df2 = df2.drop(['board', 'action', 'state'], axis=1)\n",
    "\n",
    "data_np = df2.to_numpy()\n",
    "\n",
    "current_player_data = data_np[:,0:1]\n",
    "player1_channel = (data_np[:,1:10] == 1).astype(int)\n",
    "player2_channel = (data_np[:,1:10] == 2).astype(int)\n",
    "state_data = np.concatenate([current_player_data, player1_channel, player2_channel], axis=1)\n",
    "action_data = data_np[:,10:]\n",
    "\n",
    "sample_idx = np.random.choice(state_data.shape[0], 5, replace=False)\n",
    "\n",
    "print(df2.iloc[sample_idx])\n",
    "print(state_data[sample_idx,:])\n",
    "print(action_data[sample_idx,:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data into training and test datasets. We assign a random 80% of the data to the training dataset and 20% to the test dataset. We have 3,616 rows in the training data and 904 rows in the test data, for a total of 4,520 rows (corresponding to the number of valid non-terminal board states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3616, 19)\n",
      "(3616, 9)\n",
      "(904, 19)\n",
      "(904, 9)\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.8\n",
    "\n",
    "train_idx = np.random.choice(state_data.shape[0], int(state_data.shape[0] * train_test_split), replace=False)\n",
    "train_state_data = state_data[train_idx]\n",
    "train_action_data = action_data[train_idx]\n",
    "test_state_data = np.delete(state_data, train_idx, axis=0)\n",
    "test_action_data = np.delete(action_data, train_idx, axis=0)\n",
    "\n",
    "print(train_state_data.shape)\n",
    "print(train_action_data.shape)\n",
    "print(test_state_data.shape)\n",
    "print(test_action_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a PyTorch Dataset each for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class TicTacToeDataset(Dataset):\n",
    "    def __init__(self, state_data, action_data):\n",
    "        self.state_data = state_data\n",
    "        self.action_data = action_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.state_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.state_data[idx, :], self.action_data[idx, :]\n",
    "\n",
    "train_ds = TicTacToeDataset(train_state_data, train_action_data)\n",
    "test_ds = TicTacToeDataset(test_state_data, test_action_data)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 1.19745, Test Loss: 1.24235\n",
      "Epoch: 20, Train Loss: 0.85133, Test Loss: 0.95503\n",
      "Epoch: 30, Train Loss: 0.67318, Test Loss: 0.79425\n",
      "Epoch: 40, Train Loss: 0.55312, Test Loss: 0.71450\n",
      "Epoch: 50, Train Loss: 0.47098, Test Loss: 0.62849\n",
      "Epoch: 60, Train Loss: 0.41272, Test Loss: 0.59147\n",
      "Epoch: 70, Train Loss: 0.36733, Test Loss: 0.55804\n",
      "Epoch: 80, Train Loss: 0.33168, Test Loss: 0.56320\n",
      "Epoch: 90, Train Loss: 0.30116, Test Loss: 0.52988\n",
      "Epoch: 100, Train Loss: 0.27625, Test Loss: 0.52523\n",
      "Epoch: 110, Train Loss: 0.25317, Test Loss: 0.50994\n",
      "Epoch: 120, Train Loss: 0.23210, Test Loss: 0.52215\n",
      "Epoch: 130, Train Loss: 0.21351, Test Loss: 0.50712\n",
      "Epoch: 140, Train Loss: 0.19699, Test Loss: 0.51592\n",
      "Epoch: 150, Train Loss: 0.18181, Test Loss: 0.50446\n",
      "Epoch: 160, Train Loss: 0.16726, Test Loss: 0.51125\n",
      "Epoch: 170, Train Loss: 0.15374, Test Loss: 0.50968\n",
      "Epoch: 180, Train Loss: 0.14128, Test Loss: 0.54236\n",
      "Epoch: 190, Train Loss: 0.13176, Test Loss: 0.52450\n",
      "Epoch: 200, Train Loss: 0.12027, Test Loss: 0.52291\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer1_size, layer2_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(19, layer1_size)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(layer1_size, layer2_size)  # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(layer2_size, 9)   # Fully connected layer 3 (output layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_model(train_dataloader, test_dataloader, n_epochs, layer1_size, layer2_size, lr=0.01):\n",
    "\n",
    "    # Create an instance of the neural network\n",
    "    model = NeuralNetwork(layer1_size, layer2_size)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, targets in train_dataloader:\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            probabilities = F.softmax(outputs, dim=1)  # Apply softmax activation\n",
    "            _, predicted = torch.max(probabilities, 1)  # Get the index of the highest probability\n",
    "            \n",
    "            train_loss = criterion(outputs, targets.float())\n",
    "            train_running_loss += train_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss at every 10th epoch\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            avg_train_loss = train_running_loss / len(train_dataloader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            model.eval()\n",
    "            test_running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in test_dataloader:\n",
    "\n",
    "                    outputs = model(inputs.float())\n",
    "                    test_loss = criterion(outputs, targets.float())\n",
    "                    test_running_loss += test_loss.item()\n",
    "\n",
    "                avg_test_loss = test_running_loss / len(test_dataloader)\n",
    "                test_losses.append(avg_test_loss)\n",
    "                print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:0.5f}, Test Loss: {avg_test_loss:0.5f}')\n",
    "\n",
    "    # Get the final predicted class\n",
    "    _, final_predicted = torch.max(probabilities, 1)\n",
    "\n",
    "    return model, train_losses, test_losses\n",
    "\n",
    "n_epochs = 200\n",
    "layer1_size = 1024\n",
    "layer2_size = 1024\n",
    "model, train_losses, test_losses = train_model(train_dataloader, test_dataloader, n_epochs, layer1_size, layer2_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the train losss continues to decline, while the test loss has plateaud around 0.5 or so."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at entries where this model does poorly. One thing to note is that, in tic-tac-toe, there can multiple optimal moves for a given board state. Since our training data contains only a single optimal action per state, we may be classifying as errors some predictions which result in optimal play.\n",
    "\n",
    "To deal with this, our solver can also output *all* possible optimal moves for a given board state. We can look at the neural net's predictions for a given board state and assess how many are not in the set of all optimal actions for that game state.\n",
    "\n",
    "Let's do this for all states in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 102 errors out of 904 test samples.\n"
     ]
    }
   ],
   "source": [
    "multiple_actions_dict = solver.multiple_actions_dict\n",
    "\n",
    "def state_from_mat(mat):\n",
    "    player_data = mat[0]\n",
    "    p1_data = mat[1:10]\n",
    "    p2_data = mat[10:19]\n",
    "    return (player_data, tuple(p1_data * 1 + p2_data * 2))\n",
    "\n",
    "inputs_vec = []\n",
    "targets_vec = []\n",
    "probs_vec = []\n",
    "errors_vec = []\n",
    "\n",
    "# for inputs, targets in single_dataloader:\n",
    "inputs, targets = test_ds[:]\n",
    "\n",
    "outputs = model(torch.from_numpy(inputs).float())\n",
    "probabilities = F.softmax(outputs, dim=1)\n",
    "predict_actions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "error_idx = []\n",
    "for i in range(len(inputs)):\n",
    "    predict_action = predict_actions[i].item()\n",
    "\n",
    "    if predict_action in multiple_actions_dict[state_from_mat(inputs[i])]:\n",
    "        error = 0.0\n",
    "    else:\n",
    "        error = 1.0\n",
    "        error_idx.append(i)\n",
    "n_errors = len(error_idx)\n",
    "print(f'We have {n_errors} errors out of {len(inputs)} test samples.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine a few examples of states where we have errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example #1\n",
      "Active player: 2\n",
      "Board:\n",
      "(1, 2, 1)\n",
      "(1, 0, 2)\n",
      "(0, 0, 0)\n",
      "Target (i.e. optimal action according to solver):\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[1 0 0]\n",
      "Optimal action according to neural net:\n",
      "[0 0 0]\n",
      "[0 1 0]\n",
      "[0 0 0]\n",
      "Action probabilities according to neural net:\n",
      "[7.1795661e-08 4.7225498e-08 2.1284283e-07]\n",
      "[4.5707097e-06 9.7259074e-01 7.7326625e-09]\n",
      "[2.6755188e-02 6.3632248e-04 1.2866872e-05]\n",
      "\n",
      "Example #2\n",
      "Active player: 2\n",
      "Board:\n",
      "(1, 2, 1)\n",
      "(0, 1, 2)\n",
      "(2, 1, 0)\n",
      "Target (i.e. optimal action according to solver):\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 1]\n",
      "Optimal action according to neural net:\n",
      "[0 0 0]\n",
      "[1 0 0]\n",
      "[0 0 0]\n",
      "Action probabilities according to neural net:\n",
      "[9.5932783e-06 2.7670898e-05 4.0982563e-06]\n",
      "[5.2594292e-01 1.9856998e-06 1.2750725e-06]\n",
      "[4.2330477e-05 7.3809890e-05 4.7389629e-01]\n",
      "\n",
      "Example #3\n",
      "Active player: 1\n",
      "Board:\n",
      "(1, 2, 1)\n",
      "(0, 1, 2)\n",
      "(2, 0, 0)\n",
      "Target (i.e. optimal action according to solver):\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 1]\n",
      "Optimal action according to neural net:\n",
      "[0 0 0]\n",
      "[1 0 0]\n",
      "[0 0 0]\n",
      "Action probabilities according to neural net:\n",
      "[4.0669929e-05 4.2807475e-05 8.4560070e-06]\n",
      "[8.0939001e-01 1.7846187e-07 2.8277625e-06]\n",
      "[3.1919285e-06 4.2818155e-02 1.4769369e-01]\n",
      "\n",
      "Example #4\n",
      "Active player: 1\n",
      "Board:\n",
      "(1, 2, 1)\n",
      "(0, 0, 2)\n",
      "(2, 0, 1)\n",
      "Target (i.e. optimal action according to solver):\n",
      "[0 0 0]\n",
      "[0 1 0]\n",
      "[0 0 0]\n",
      "Optimal action according to neural net:\n",
      "[0 0 0]\n",
      "[1 0 0]\n",
      "[0 0 0]\n",
      "Action probabilities according to neural net:\n",
      "[7.4526392e-06 1.2831084e-05 2.3809184e-06]\n",
      "[5.6145149e-01 4.3721297e-01 2.7234321e-07]\n",
      "[5.8024239e-09 1.3119604e-03 6.4821285e-07]\n",
      "\n",
      "Example #5\n",
      "Active player: 2\n",
      "Board:\n",
      "(1, 2, 1)\n",
      "(1, 0, 0)\n",
      "(2, 0, 0)\n",
      "Target (i.e. optimal action according to solver):\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 1 0]\n",
      "Optimal action according to neural net:\n",
      "[0 0 0]\n",
      "[0 1 0]\n",
      "[0 0 0]\n",
      "Action probabilities according to neural net:\n",
      "[2.9910932e-08 5.3376266e-07 5.0426928e-07]\n",
      "[2.9707589e-06 9.6668452e-01 5.4177106e-04]\n",
      "[4.1024256e-07 2.6694551e-02 6.0745855e-03]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    state = state_from_mat(inputs[error_idx[i], :])\n",
    "    player, board = state\n",
    "    target = targets[error_idx[i], :]\n",
    "    probs = probabilities[error_idx[i], :].detach().numpy()\n",
    "    print(f'Example #{i+1}')\n",
    "    print('Active player: ' + str(player+1))\n",
    "    print('Board:')\n",
    "    print(str(board[0:3]) + \"\\n\" + str(board[3:6]) + \"\\n\" + str(board[6:9]))\n",
    "    print('Target (i.e. optimal action according to solver):')\n",
    "    print(str(target[0:3]) + \"\\n\" + str(target[3:6]) + \"\\n\" + str(target[6:9]))\n",
    "    print('Optimal action according to neural net:')\n",
    "    nn_action = np.zeros(9, dtype=int)\n",
    "    nn_action[predict_actions[error_idx[i]].item()] = 1\n",
    "    print(str(nn_action[0:3]) + \"\\n\" + str(nn_action[3:6]) + \"\\n\" + str(nn_action[6:9]))\n",
    "    print('Action probabilities according to neural net:')\n",
    "    print(str(probs[0:3]) + \"\\n\" + str(probs[3:6]) + \"\\n\" + str(probs[6:9]))\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five examples above show that the neural net's errors are indeed mistakes. The neural net misses immediate winning moves (examples #3 and #4) or moves that block an immediate opponent win (examples #1 and #2). Only example #5 has any subtlety to it: it only becomes apparent after two moves that the neural net's action is suboptimal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried to improve the neural net's performance by increasing the size of the hidden layers and by adding an additional layer. However, no matter what configuration I try, the neural net's test loss hovers around 0.5 or 0.45, and the 'error' moves persist.\n",
    "\n",
    "\n",
    "Although we can't attain perfect performance on the test data, I'm also interested in knowing how well the model can perform on the training dataset itself. Typically, we don't to optimize for performance on a training data because this risks overfitting, where the model is trained on specific characteristics of the training set and doesn't generalize well to other data.\n",
    "\n",
    "However, in this case, we have the entire dataset of optimal play and we are interested in understanding whether the optimal (call it the `policy function') can be represented as a neural network.\n",
    "\n",
    "So let's use the entire dataset as our training dataset and try to minize the training loss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set up our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4520, 19)\n",
      "(4520, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_state_data = state_data\n",
    "train_action_data = action_data\n",
    "\n",
    "print(train_state_data.shape)\n",
    "print(train_action_data.shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class TicTacToeDataset(Dataset):\n",
    "    def __init__(self, state_data, action_data):\n",
    "        self.state_data = state_data\n",
    "        self.action_data = action_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.state_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.state_data[idx, :], self.action_data[idx, :]\n",
    "\n",
    "train_ds = TicTacToeDataset(train_state_data, train_action_data)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to increase the number of training steps relative to what we used before. We will also decrease the size of the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 1.92973\n",
      "Epoch: 20, Train Loss: 1.47595\n",
      "Epoch: 30, Train Loss: 1.24634\n",
      "Epoch: 40, Train Loss: 1.07878\n",
      "Epoch: 50, Train Loss: 0.90451\n",
      "Epoch: 60, Train Loss: 0.78146\n",
      "Epoch: 70, Train Loss: 0.69240\n",
      "Epoch: 80, Train Loss: 0.62658\n",
      "Epoch: 90, Train Loss: 0.57745\n",
      "Epoch: 100, Train Loss: 0.53531\n",
      "Epoch: 110, Train Loss: 0.49794\n",
      "Epoch: 120, Train Loss: 0.46679\n",
      "Epoch: 130, Train Loss: 0.43869\n",
      "Epoch: 140, Train Loss: 0.41384\n",
      "Epoch: 150, Train Loss: 0.39635\n",
      "Epoch: 160, Train Loss: 0.37595\n",
      "Epoch: 170, Train Loss: 0.36036\n",
      "Epoch: 180, Train Loss: 0.34194\n",
      "Epoch: 190, Train Loss: 0.32994\n",
      "Epoch: 200, Train Loss: 0.31617\n",
      "Epoch: 210, Train Loss: 0.30799\n",
      "Epoch: 220, Train Loss: 0.29619\n",
      "Epoch: 230, Train Loss: 0.28416\n",
      "Epoch: 240, Train Loss: 0.27545\n",
      "Epoch: 250, Train Loss: 0.26795\n",
      "Epoch: 260, Train Loss: 0.26162\n",
      "Epoch: 270, Train Loss: 0.25297\n",
      "Epoch: 280, Train Loss: 0.24906\n",
      "Epoch: 290, Train Loss: 0.23940\n",
      "Epoch: 300, Train Loss: 0.23367\n",
      "Epoch: 310, Train Loss: 0.22976\n",
      "Epoch: 320, Train Loss: 0.22300\n",
      "Epoch: 330, Train Loss: 0.21650\n",
      "Epoch: 340, Train Loss: 0.21361\n",
      "Epoch: 350, Train Loss: 0.20617\n",
      "Epoch: 360, Train Loss: 0.20311\n",
      "Epoch: 370, Train Loss: 0.19722\n",
      "Epoch: 380, Train Loss: 0.19303\n",
      "Epoch: 390, Train Loss: 0.19119\n",
      "Epoch: 400, Train Loss: 0.18447\n",
      "Epoch: 410, Train Loss: 0.18160\n",
      "Epoch: 420, Train Loss: 0.17590\n",
      "Epoch: 430, Train Loss: 0.16890\n",
      "Epoch: 440, Train Loss: 0.16609\n",
      "Epoch: 450, Train Loss: 0.16383\n",
      "Epoch: 460, Train Loss: 0.15843\n",
      "Epoch: 470, Train Loss: 0.15489\n",
      "Epoch: 480, Train Loss: 0.15272\n",
      "Epoch: 490, Train Loss: 0.14738\n",
      "Epoch: 500, Train Loss: 0.14235\n",
      "Epoch: 510, Train Loss: 0.13898\n",
      "Epoch: 520, Train Loss: 0.13653\n",
      "Epoch: 530, Train Loss: 0.13342\n",
      "Epoch: 540, Train Loss: 0.12963\n",
      "Epoch: 550, Train Loss: 0.12562\n",
      "Epoch: 560, Train Loss: 0.12441\n",
      "Epoch: 570, Train Loss: 0.12009\n",
      "Epoch: 580, Train Loss: 0.11741\n",
      "Epoch: 590, Train Loss: 0.11380\n",
      "Epoch: 600, Train Loss: 0.11015\n",
      "Epoch: 610, Train Loss: 0.10726\n",
      "Epoch: 620, Train Loss: 0.10253\n",
      "Epoch: 630, Train Loss: 0.10250\n",
      "Epoch: 640, Train Loss: 0.09815\n",
      "Epoch: 650, Train Loss: 0.09551\n",
      "Epoch: 660, Train Loss: 0.09379\n",
      "Epoch: 670, Train Loss: 0.08948\n",
      "Epoch: 680, Train Loss: 0.08641\n",
      "Epoch: 690, Train Loss: 0.08439\n",
      "Epoch: 700, Train Loss: 0.08490\n",
      "Epoch: 710, Train Loss: 0.08101\n",
      "Epoch: 720, Train Loss: 0.08046\n",
      "Epoch: 730, Train Loss: 0.07578\n",
      "Epoch: 740, Train Loss: 0.07630\n",
      "Epoch: 750, Train Loss: 0.07218\n",
      "Epoch: 760, Train Loss: 0.06955\n",
      "Epoch: 770, Train Loss: 0.06734\n",
      "Epoch: 780, Train Loss: 0.06904\n",
      "Epoch: 790, Train Loss: 0.06393\n",
      "Epoch: 800, Train Loss: 0.06329\n",
      "Epoch: 810, Train Loss: 0.06138\n",
      "Epoch: 820, Train Loss: 0.05845\n",
      "Epoch: 830, Train Loss: 0.05723\n",
      "Epoch: 840, Train Loss: 0.05535\n",
      "Epoch: 850, Train Loss: 0.05381\n",
      "Epoch: 860, Train Loss: 0.05177\n",
      "Epoch: 870, Train Loss: 0.05128\n",
      "Epoch: 880, Train Loss: 0.04949\n",
      "Epoch: 890, Train Loss: 0.04780\n",
      "Epoch: 900, Train Loss: 0.04552\n",
      "Epoch: 910, Train Loss: 0.04496\n",
      "Epoch: 920, Train Loss: 0.04287\n",
      "Epoch: 930, Train Loss: 0.04354\n",
      "Epoch: 940, Train Loss: 0.04041\n",
      "Epoch: 950, Train Loss: 0.03917\n",
      "Epoch: 960, Train Loss: 0.03991\n",
      "Epoch: 970, Train Loss: 0.03806\n",
      "Epoch: 980, Train Loss: 0.03502\n",
      "Epoch: 990, Train Loss: 0.03463\n",
      "Epoch: 1000, Train Loss: 0.03355\n",
      "Epoch: 1010, Train Loss: 0.03249\n",
      "Epoch: 1020, Train Loss: 0.03191\n",
      "Epoch: 1030, Train Loss: 0.03155\n",
      "Epoch: 1040, Train Loss: 0.03008\n",
      "Epoch: 1050, Train Loss: 0.02858\n",
      "Epoch: 1060, Train Loss: 0.02801\n",
      "Epoch: 1070, Train Loss: 0.02778\n",
      "Epoch: 1080, Train Loss: 0.02653\n",
      "Epoch: 1090, Train Loss: 0.02668\n",
      "Epoch: 1100, Train Loss: 0.02508\n",
      "Epoch: 1110, Train Loss: 0.02440\n",
      "Epoch: 1120, Train Loss: 0.02439\n",
      "Epoch: 1130, Train Loss: 0.02328\n",
      "Epoch: 1140, Train Loss: 0.02256\n",
      "Epoch: 1150, Train Loss: 0.02172\n",
      "Epoch: 1160, Train Loss: 0.02146\n",
      "Epoch: 1170, Train Loss: 0.02042\n",
      "Epoch: 1180, Train Loss: 0.02046\n",
      "Epoch: 1190, Train Loss: 0.01994\n",
      "Epoch: 1200, Train Loss: 0.01966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer1_size, layer2_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(19, layer1_size)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(layer1_size, layer2_size)  # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(layer2_size, 9)   # Fully connected layer 3 (output layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_model(train_dataloader, n_epochs, layer1_size, layer2_size, lr=0.01):\n",
    "\n",
    "    # Create an instance of the neural network\n",
    "    model = NeuralNetwork(layer1_size, layer2_size)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, targets in train_dataloader:\n",
    "            # inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "            # targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            probabilities = F.softmax(outputs, dim=1)  # Apply softmax activation\n",
    "            _, predicted = torch.max(probabilities, 1)  # Get the index of the highest probability\n",
    "            \n",
    "            train_loss = criterion(outputs, targets.float())\n",
    "            train_running_loss += train_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss at every 10th epoch\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            avg_train_loss = train_running_loss / len(train_dataloader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "           \n",
    "            print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:0.5f}')\n",
    "\n",
    "    # Get the final predicted class\n",
    "    _, final_predicted = torch.max(probabilities, 1)\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "n_epochs = 1200\n",
    "layer1_size = 50\n",
    "layer2_size = 50\n",
    "model, train_losses = train_model(train_dataloader, n_epochs, layer1_size, layer2_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, let's see how many errors we have in the neural net's predictions. However, this time we evaluate the neural network on the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def state_from_mat(mat):\n",
    "    player_data = mat[0]\n",
    "    p1_data = mat[1:10]\n",
    "    p2_data = mat[10:19]\n",
    "    return (player_data, tuple(p1_data * 1 + p2_data * 2))\n",
    "\n",
    "inputs_vec = []\n",
    "targets_vec = []\n",
    "probs_vec = []\n",
    "errors_vec = []\n",
    "\n",
    "# for inputs, targets in single_dataloader:\n",
    "inputs, targets = train_ds[:]\n",
    "\n",
    "outputs = model(torch.from_numpy(inputs).float())\n",
    "probabilities = F.softmax(outputs, dim=1)\n",
    "predict_actions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "error_idx = []\n",
    "for i in range(len(inputs)):\n",
    "    predict_action = predict_actions[i].item()\n",
    "\n",
    "    if predict_action in multiple_actions_dict[state_from_mat(inputs[i])]:\n",
    "        error = 0.0\n",
    "    else:\n",
    "        error = 1.0\n",
    "        error_idx.append(i)\n",
    "print(len(error_idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have zero errors, meaning that our neural net has successfully learned optimal play for tic-tac-toe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
